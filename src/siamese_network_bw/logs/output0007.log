I0607 21:45:21.322903 1956823808 caffe.cpp:113] Use GPU with device ID 0
I0607 21:45:22.087549 1956823808 caffe.cpp:121] Starting Optimization
I0607 21:45:22.087576 1956823808 solver.cpp:32] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.001
display: 100
max_iter: 1500
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0
snapshot: 0
snapshot_prefix: "src/siamese_network_bw/model/snapshots/siamese"
solver_mode: GPU
net: "src/siamese_network_bw/model/siamese_train_validate.prototxt"
I0607 21:45:22.087662 1956823808 solver.cpp:70] Creating training net from net file: src/siamese_network_bw/model/siamese_train_validate.prototxt
I0607 21:45:22.088135 1956823808 net.cpp:287] The NetState phase (0) differed from the phase (1) specified by a rule in layer pair_data
I0607 21:45:22.088166 1956823808 net.cpp:42] Initializing net from parameters: 
name: "siamese_train_validate"
state {
  phase: TRAIN
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 1
  }
  data_param {
    source: "src/siamese_network_bw/data/siamese_network_train_leveldb"
    batch_size: 64
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "pool2_p"
  top: "conv3_p"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool3_p"
  type: "Pooling"
  bottom: "conv3_p"
  top: "pool3_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool3_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0607 21:45:22.088448 1956823808 layer_factory.hpp:74] Creating layer pair_data
I0607 21:45:22.088465 1956823808 net.cpp:90] Creating Layer pair_data
I0607 21:45:22.088506 1956823808 net.cpp:368] pair_data -> pair_data
I0607 21:45:22.088546 1956823808 net.cpp:368] pair_data -> sim
I0607 21:45:22.088559 1956823808 net.cpp:120] Setting up pair_data
I0607 21:45:22.090903 1956823808 db.cpp:20] Opened leveldb src/siamese_network_bw/data/siamese_network_train_leveldb
I0607 21:45:22.091285 1956823808 data_layer.cpp:52] output data size: 64,2,62,47
I0607 21:45:22.092008 1956823808 net.cpp:127] Top shape: 64 2 62 47 (372992)
I0607 21:45:22.092034 1956823808 net.cpp:127] Top shape: 64 (64)
I0607 21:45:22.092046 1956823808 layer_factory.hpp:74] Creating layer slice_pair
I0607 21:45:22.092061 1956823808 net.cpp:90] Creating Layer slice_pair
I0607 21:45:22.092067 1956823808 net.cpp:410] slice_pair <- pair_data
I0607 21:45:22.092077 1956823808 net.cpp:368] slice_pair -> data
I0607 21:45:22.092090 1956823808 net.cpp:368] slice_pair -> data_p
I0607 21:45:22.092097 1956823808 net.cpp:120] Setting up slice_pair
I0607 21:45:22.092118 1956823808 net.cpp:127] Top shape: 64 1 62 47 (186496)
I0607 21:45:22.092139 1956823808 net.cpp:127] Top shape: 64 1 62 47 (186496)
I0607 21:45:22.092150 1956823808 layer_factory.hpp:74] Creating layer conv1
I0607 21:45:22.092164 1956823808 net.cpp:90] Creating Layer conv1
I0607 21:45:22.092181 1956823808 net.cpp:410] conv1 <- data
I0607 21:45:22.092195 1956823808 net.cpp:368] conv1 -> conv1
I0607 21:45:22.092211 1956823808 net.cpp:120] Setting up conv1
I0607 21:45:22.146772 1956823808 net.cpp:127] Top shape: 64 32 60 45 (5529600)
I0607 21:45:22.146811 1956823808 layer_factory.hpp:74] Creating layer pool1
I0607 21:45:22.146842 1956823808 net.cpp:90] Creating Layer pool1
I0607 21:45:22.146848 1956823808 net.cpp:410] pool1 <- conv1
I0607 21:45:22.146854 1956823808 net.cpp:368] pool1 -> pool1
I0607 21:45:22.146862 1956823808 net.cpp:120] Setting up pool1
I0607 21:45:22.147059 1956823808 net.cpp:127] Top shape: 64 32 30 23 (1413120)
I0607 21:45:22.147074 1956823808 layer_factory.hpp:74] Creating layer conv2
I0607 21:45:22.147088 1956823808 net.cpp:90] Creating Layer conv2
I0607 21:45:22.147091 1956823808 net.cpp:410] conv2 <- pool1
I0607 21:45:22.147099 1956823808 net.cpp:368] conv2 -> conv2
I0607 21:45:22.147106 1956823808 net.cpp:120] Setting up conv2
I0607 21:45:22.147383 1956823808 net.cpp:127] Top shape: 64 64 29 22 (2613248)
I0607 21:45:22.147395 1956823808 layer_factory.hpp:74] Creating layer pool2
I0607 21:45:22.147404 1956823808 net.cpp:90] Creating Layer pool2
I0607 21:45:22.147408 1956823808 net.cpp:410] pool2 <- conv2
I0607 21:45:22.147413 1956823808 net.cpp:368] pool2 -> pool2
I0607 21:45:22.147418 1956823808 net.cpp:120] Setting up pool2
I0607 21:45:22.147511 1956823808 net.cpp:127] Top shape: 64 64 15 11 (675840)
I0607 21:45:22.147527 1956823808 layer_factory.hpp:74] Creating layer conv3
I0607 21:45:22.147536 1956823808 net.cpp:90] Creating Layer conv3
I0607 21:45:22.147542 1956823808 net.cpp:410] conv3 <- pool2
I0607 21:45:22.147553 1956823808 net.cpp:368] conv3 -> conv3
I0607 21:45:22.147563 1956823808 net.cpp:120] Setting up conv3
I0607 21:45:22.148236 1956823808 net.cpp:127] Top shape: 64 128 14 10 (1146880)
I0607 21:45:22.148252 1956823808 layer_factory.hpp:74] Creating layer pool3
I0607 21:45:22.148258 1956823808 net.cpp:90] Creating Layer pool3
I0607 21:45:22.148262 1956823808 net.cpp:410] pool3 <- conv3
I0607 21:45:22.148267 1956823808 net.cpp:368] pool3 -> pool3
I0607 21:45:22.148273 1956823808 net.cpp:120] Setting up pool3
I0607 21:45:22.148318 1956823808 net.cpp:127] Top shape: 64 128 7 5 (286720)
I0607 21:45:22.148324 1956823808 layer_factory.hpp:74] Creating layer ip1
I0607 21:45:22.148334 1956823808 net.cpp:90] Creating Layer ip1
I0607 21:45:22.148339 1956823808 net.cpp:410] ip1 <- pool3
I0607 21:45:22.148344 1956823808 net.cpp:368] ip1 -> ip1
I0607 21:45:22.148350 1956823808 net.cpp:120] Setting up ip1
I0607 21:45:22.166944 1956823808 net.cpp:127] Top shape: 64 500 (32000)
I0607 21:45:22.166985 1956823808 layer_factory.hpp:74] Creating layer relu1
I0607 21:45:22.167029 1956823808 net.cpp:90] Creating Layer relu1
I0607 21:45:22.167042 1956823808 net.cpp:410] relu1 <- ip1
I0607 21:45:22.167050 1956823808 net.cpp:357] relu1 -> ip1 (in-place)
I0607 21:45:22.167057 1956823808 net.cpp:120] Setting up relu1
I0607 21:45:22.167309 1956823808 net.cpp:127] Top shape: 64 500 (32000)
I0607 21:45:22.167322 1956823808 layer_factory.hpp:74] Creating layer ip2
I0607 21:45:22.167335 1956823808 net.cpp:90] Creating Layer ip2
I0607 21:45:22.167340 1956823808 net.cpp:410] ip2 <- ip1
I0607 21:45:22.167347 1956823808 net.cpp:368] ip2 -> ip2
I0607 21:45:22.167356 1956823808 net.cpp:120] Setting up ip2
I0607 21:45:22.167417 1956823808 net.cpp:127] Top shape: 64 10 (640)
I0607 21:45:22.167426 1956823808 layer_factory.hpp:74] Creating layer feat
I0607 21:45:22.167434 1956823808 net.cpp:90] Creating Layer feat
I0607 21:45:22.167438 1956823808 net.cpp:410] feat <- ip2
I0607 21:45:22.167443 1956823808 net.cpp:368] feat -> feat
I0607 21:45:22.167450 1956823808 net.cpp:120] Setting up feat
I0607 21:45:22.167459 1956823808 net.cpp:127] Top shape: 64 2 (128)
I0607 21:45:22.167464 1956823808 layer_factory.hpp:74] Creating layer conv1_p
I0607 21:45:22.167471 1956823808 net.cpp:90] Creating Layer conv1_p
I0607 21:45:22.167474 1956823808 net.cpp:410] conv1_p <- data_p
I0607 21:45:22.167482 1956823808 net.cpp:368] conv1_p -> conv1_p
I0607 21:45:22.167490 1956823808 net.cpp:120] Setting up conv1_p
I0607 21:45:22.167721 1956823808 net.cpp:127] Top shape: 64 32 60 45 (5529600)
I0607 21:45:22.167731 1956823808 net.cpp:459] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0607 21:45:22.167771 1956823808 net.cpp:459] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0607 21:45:22.167778 1956823808 layer_factory.hpp:74] Creating layer pool1_p
I0607 21:45:22.167789 1956823808 net.cpp:90] Creating Layer pool1_p
I0607 21:45:22.167794 1956823808 net.cpp:410] pool1_p <- conv1_p
I0607 21:45:22.167799 1956823808 net.cpp:368] pool1_p -> pool1_p
I0607 21:45:22.167805 1956823808 net.cpp:120] Setting up pool1_p
I0607 21:45:22.167853 1956823808 net.cpp:127] Top shape: 64 32 30 23 (1413120)
I0607 21:45:22.167860 1956823808 layer_factory.hpp:74] Creating layer conv2_p
I0607 21:45:22.167866 1956823808 net.cpp:90] Creating Layer conv2_p
I0607 21:45:22.167870 1956823808 net.cpp:410] conv2_p <- pool1_p
I0607 21:45:22.167876 1956823808 net.cpp:368] conv2_p -> conv2_p
I0607 21:45:22.167881 1956823808 net.cpp:120] Setting up conv2_p
I0607 21:45:22.168156 1956823808 net.cpp:127] Top shape: 64 64 29 22 (2613248)
I0607 21:45:22.168167 1956823808 net.cpp:459] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0607 21:45:22.168172 1956823808 net.cpp:459] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0607 21:45:22.168177 1956823808 layer_factory.hpp:74] Creating layer pool2_p
I0607 21:45:22.168184 1956823808 net.cpp:90] Creating Layer pool2_p
I0607 21:45:22.168186 1956823808 net.cpp:410] pool2_p <- conv2_p
I0607 21:45:22.168191 1956823808 net.cpp:368] pool2_p -> pool2_p
I0607 21:45:22.168200 1956823808 net.cpp:120] Setting up pool2_p
I0607 21:45:22.168244 1956823808 net.cpp:127] Top shape: 64 64 15 11 (675840)
I0607 21:45:22.168251 1956823808 layer_factory.hpp:74] Creating layer conv3_p
I0607 21:45:22.168261 1956823808 net.cpp:90] Creating Layer conv3_p
I0607 21:45:22.168264 1956823808 net.cpp:410] conv3_p <- pool2_p
I0607 21:45:22.168270 1956823808 net.cpp:368] conv3_p -> conv3_p
I0607 21:45:22.168277 1956823808 net.cpp:120] Setting up conv3_p
I0607 21:45:22.168853 1956823808 net.cpp:127] Top shape: 64 128 14 10 (1146880)
I0607 21:45:22.168867 1956823808 net.cpp:459] Sharing parameters 'conv3_w' owned by layer 'conv3', param index 0
I0607 21:45:22.168877 1956823808 net.cpp:459] Sharing parameters 'conv3_b' owned by layer 'conv3', param index 1
I0607 21:45:22.168886 1956823808 layer_factory.hpp:74] Creating layer pool3_p
I0607 21:45:22.168895 1956823808 net.cpp:90] Creating Layer pool3_p
I0607 21:45:22.168910 1956823808 net.cpp:410] pool3_p <- conv3_p
I0607 21:45:22.168922 1956823808 net.cpp:368] pool3_p -> pool3_p
I0607 21:45:22.168946 1956823808 net.cpp:120] Setting up pool3_p
I0607 21:45:22.169042 1956823808 net.cpp:127] Top shape: 64 128 7 5 (286720)
I0607 21:45:22.169052 1956823808 layer_factory.hpp:74] Creating layer ip1_p
I0607 21:45:22.169060 1956823808 net.cpp:90] Creating Layer ip1_p
I0607 21:45:22.169064 1956823808 net.cpp:410] ip1_p <- pool3_p
I0607 21:45:22.169081 1956823808 net.cpp:368] ip1_p -> ip1_p
I0607 21:45:22.169103 1956823808 net.cpp:120] Setting up ip1_p
I0607 21:45:22.187409 1956823808 net.cpp:127] Top shape: 64 500 (32000)
I0607 21:45:22.187428 1956823808 net.cpp:459] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I0607 21:45:22.187448 1956823808 net.cpp:459] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I0607 21:45:22.187453 1956823808 layer_factory.hpp:74] Creating layer relu1_p
I0607 21:45:22.187461 1956823808 net.cpp:90] Creating Layer relu1_p
I0607 21:45:22.187466 1956823808 net.cpp:410] relu1_p <- ip1_p
I0607 21:45:22.187471 1956823808 net.cpp:357] relu1_p -> ip1_p (in-place)
I0607 21:45:22.187479 1956823808 net.cpp:120] Setting up relu1_p
I0607 21:45:22.187644 1956823808 net.cpp:127] Top shape: 64 500 (32000)
I0607 21:45:22.187654 1956823808 layer_factory.hpp:74] Creating layer ip2_p
I0607 21:45:22.187664 1956823808 net.cpp:90] Creating Layer ip2_p
I0607 21:45:22.187667 1956823808 net.cpp:410] ip2_p <- ip1_p
I0607 21:45:22.187674 1956823808 net.cpp:368] ip2_p -> ip2_p
I0607 21:45:22.187681 1956823808 net.cpp:120] Setting up ip2_p
I0607 21:45:22.187733 1956823808 net.cpp:127] Top shape: 64 10 (640)
I0607 21:45:22.187755 1956823808 net.cpp:459] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I0607 21:45:22.187762 1956823808 net.cpp:459] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I0607 21:45:22.187767 1956823808 layer_factory.hpp:74] Creating layer feat_p
I0607 21:45:22.187773 1956823808 net.cpp:90] Creating Layer feat_p
I0607 21:45:22.187777 1956823808 net.cpp:410] feat_p <- ip2_p
I0607 21:45:22.187785 1956823808 net.cpp:368] feat_p -> feat_p
I0607 21:45:22.187793 1956823808 net.cpp:120] Setting up feat_p
I0607 21:45:22.187800 1956823808 net.cpp:127] Top shape: 64 2 (128)
I0607 21:45:22.187805 1956823808 net.cpp:459] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I0607 21:45:22.187810 1956823808 net.cpp:459] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I0607 21:45:22.187814 1956823808 layer_factory.hpp:74] Creating layer loss
I0607 21:45:22.187824 1956823808 net.cpp:90] Creating Layer loss
I0607 21:45:22.187827 1956823808 net.cpp:410] loss <- feat
I0607 21:45:22.187831 1956823808 net.cpp:410] loss <- feat_p
I0607 21:45:22.187836 1956823808 net.cpp:410] loss <- sim
I0607 21:45:22.187841 1956823808 net.cpp:368] loss -> loss
I0607 21:45:22.187847 1956823808 net.cpp:120] Setting up loss
I0607 21:45:22.187855 1956823808 net.cpp:127] Top shape: (1)
I0607 21:45:22.187860 1956823808 net.cpp:129]     with loss weight 1
I0607 21:45:22.187871 1956823808 net.cpp:192] loss needs backward computation.
I0607 21:45:22.187875 1956823808 net.cpp:192] feat_p needs backward computation.
I0607 21:45:22.187880 1956823808 net.cpp:192] ip2_p needs backward computation.
I0607 21:45:22.187883 1956823808 net.cpp:192] relu1_p needs backward computation.
I0607 21:45:22.187887 1956823808 net.cpp:192] ip1_p needs backward computation.
I0607 21:45:22.187891 1956823808 net.cpp:192] pool3_p needs backward computation.
I0607 21:45:22.187896 1956823808 net.cpp:192] conv3_p needs backward computation.
I0607 21:45:22.187898 1956823808 net.cpp:192] pool2_p needs backward computation.
I0607 21:45:22.187902 1956823808 net.cpp:192] conv2_p needs backward computation.
I0607 21:45:22.187906 1956823808 net.cpp:192] pool1_p needs backward computation.
I0607 21:45:22.187911 1956823808 net.cpp:192] conv1_p needs backward computation.
I0607 21:45:22.187914 1956823808 net.cpp:192] feat needs backward computation.
I0607 21:45:22.187917 1956823808 net.cpp:192] ip2 needs backward computation.
I0607 21:45:22.187922 1956823808 net.cpp:192] relu1 needs backward computation.
I0607 21:45:22.187926 1956823808 net.cpp:192] ip1 needs backward computation.
I0607 21:45:22.187929 1956823808 net.cpp:192] pool3 needs backward computation.
I0607 21:45:22.187963 1956823808 net.cpp:192] conv3 needs backward computation.
I0607 21:45:22.187968 1956823808 net.cpp:192] pool2 needs backward computation.
I0607 21:45:22.187971 1956823808 net.cpp:192] conv2 needs backward computation.
I0607 21:45:22.187974 1956823808 net.cpp:192] pool1 needs backward computation.
I0607 21:45:22.187978 1956823808 net.cpp:192] conv1 needs backward computation.
I0607 21:45:22.187983 1956823808 net.cpp:194] slice_pair does not need backward computation.
I0607 21:45:22.187988 1956823808 net.cpp:194] pair_data does not need backward computation.
I0607 21:45:22.189601 1956823808 net.cpp:235] This network produces output loss
I0607 21:45:22.189626 1956823808 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0607 21:45:22.189636 1956823808 net.cpp:247] Network initialization done.
I0607 21:45:22.189640 1956823808 net.cpp:248] Memory required for data: 96825604
I0607 21:45:22.190076 1956823808 solver.cpp:154] Creating test net (#0) specified by net file: src/siamese_network_bw/model/siamese_train_validate.prototxt
I0607 21:45:22.190125 1956823808 net.cpp:287] The NetState phase (1) differed from the phase (0) specified by a rule in layer pair_data
I0607 21:45:22.190145 1956823808 net.cpp:42] Initializing net from parameters: 
name: "siamese_train_validate"
state {
  phase: TEST
}
layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include {
    phase: TEST
  }
  transform_param {
    scale: 1
  }
  data_param {
    source: "src/siamese_network_bw/data/siamese_network_validation_leveldb"
    batch_size: 100
  }
}
layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "ip1"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1_p"
  type: "Convolution"
  bottom: "data_p"
  top: "conv1_p"
  param {
    name: "conv1_w"
    lr_mult: 1
  }
  param {
    name: "conv1_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1_p"
  type: "Pooling"
  bottom: "conv1_p"
  top: "pool1_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_p"
  type: "Convolution"
  bottom: "pool1_p"
  top: "conv2_p"
  param {
    name: "conv2_w"
    lr_mult: 1
  }
  param {
    name: "conv2_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2_p"
  type: "Pooling"
  bottom: "conv2_p"
  top: "pool2_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_p"
  type: "Convolution"
  bottom: "pool2_p"
  top: "conv3_p"
  param {
    name: "conv3_w"
    lr_mult: 1
  }
  param {
    name: "conv3_b"
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool3_p"
  type: "Pooling"
  bottom: "conv3_p"
  top: "pool3_p"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1_p"
  type: "InnerProduct"
  bottom: "pool3_p"
  top: "ip1_p"
  param {
    name: "ip1_w"
    lr_mult: 1
  }
  param {
    name: "ip1_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1_p"
  type: "ReLU"
  bottom: "ip1_p"
  top: "ip1_p"
}
layer {
  name: "ip2_p"
  type: "InnerProduct"
  bottom: "ip1_p"
  top: "ip2_p"
  param {
    name: "ip2_w"
    lr_mult: 1
  }
  param {
    name: "ip2_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "feat_p"
  type: "InnerProduct"
  bottom: "ip2_p"
  top: "feat_p"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "ContrastiveLoss"
  bottom: "feat"
  bottom: "feat_p"
  bottom: "sim"
  top: "loss"
  contrastive_loss_param {
    margin: 1
  }
}
I0607 21:45:22.190410 1956823808 layer_factory.hpp:74] Creating layer pair_data
I0607 21:45:22.190419 1956823808 net.cpp:90] Creating Layer pair_data
I0607 21:45:22.190424 1956823808 net.cpp:368] pair_data -> pair_data
I0607 21:45:22.190433 1956823808 net.cpp:368] pair_data -> sim
I0607 21:45:22.190440 1956823808 net.cpp:120] Setting up pair_data
I0607 21:45:22.191601 1956823808 db.cpp:20] Opened leveldb src/siamese_network_bw/data/siamese_network_validation_leveldb
I0607 21:45:22.191831 1956823808 data_layer.cpp:52] output data size: 100,2,62,47
I0607 21:45:22.192823 1956823808 net.cpp:127] Top shape: 100 2 62 47 (582800)
I0607 21:45:22.192836 1956823808 net.cpp:127] Top shape: 100 (100)
I0607 21:45:22.192841 1956823808 layer_factory.hpp:74] Creating layer slice_pair
I0607 21:45:22.192849 1956823808 net.cpp:90] Creating Layer slice_pair
I0607 21:45:22.192854 1956823808 net.cpp:410] slice_pair <- pair_data
I0607 21:45:22.192860 1956823808 net.cpp:368] slice_pair -> data
I0607 21:45:22.192868 1956823808 net.cpp:368] slice_pair -> data_p
I0607 21:45:22.192874 1956823808 net.cpp:120] Setting up slice_pair
I0607 21:45:22.192880 1956823808 net.cpp:127] Top shape: 100 1 62 47 (291400)
I0607 21:45:22.192885 1956823808 net.cpp:127] Top shape: 100 1 62 47 (291400)
I0607 21:45:22.194494 1956823808 layer_factory.hpp:74] Creating layer conv1
I0607 21:45:22.194520 1956823808 net.cpp:90] Creating Layer conv1
I0607 21:45:22.194528 1956823808 net.cpp:410] conv1 <- data
I0607 21:45:22.194540 1956823808 net.cpp:368] conv1 -> conv1
I0607 21:45:22.194557 1956823808 net.cpp:120] Setting up conv1
I0607 21:45:22.194947 1956823808 net.cpp:127] Top shape: 100 32 60 45 (8640000)
I0607 21:45:22.194962 1956823808 layer_factory.hpp:74] Creating layer pool1
I0607 21:45:22.194969 1956823808 net.cpp:90] Creating Layer pool1
I0607 21:45:22.194973 1956823808 net.cpp:410] pool1 <- conv1
I0607 21:45:22.194983 1956823808 net.cpp:368] pool1 -> pool1
I0607 21:45:22.194993 1956823808 net.cpp:120] Setting up pool1
I0607 21:45:22.195051 1956823808 net.cpp:127] Top shape: 100 32 30 23 (2208000)
I0607 21:45:22.195061 1956823808 layer_factory.hpp:74] Creating layer conv2
I0607 21:45:22.195075 1956823808 net.cpp:90] Creating Layer conv2
I0607 21:45:22.195081 1956823808 net.cpp:410] conv2 <- pool1
I0607 21:45:22.195091 1956823808 net.cpp:368] conv2 -> conv2
I0607 21:45:22.195102 1956823808 net.cpp:120] Setting up conv2
I0607 21:45:22.195534 1956823808 net.cpp:127] Top shape: 100 64 29 22 (4083200)
I0607 21:45:22.195550 1956823808 layer_factory.hpp:74] Creating layer pool2
I0607 21:45:22.195564 1956823808 net.cpp:90] Creating Layer pool2
I0607 21:45:22.195595 1956823808 net.cpp:410] pool2 <- conv2
I0607 21:45:22.195605 1956823808 net.cpp:368] pool2 -> pool2
I0607 21:45:22.195616 1956823808 net.cpp:120] Setting up pool2
I0607 21:45:22.195683 1956823808 net.cpp:127] Top shape: 100 64 15 11 (1056000)
I0607 21:45:22.195694 1956823808 layer_factory.hpp:74] Creating layer conv3
I0607 21:45:22.195704 1956823808 net.cpp:90] Creating Layer conv3
I0607 21:45:22.195713 1956823808 net.cpp:410] conv3 <- pool2
I0607 21:45:22.195725 1956823808 net.cpp:368] conv3 -> conv3
I0607 21:45:22.195739 1956823808 net.cpp:120] Setting up conv3
I0607 21:45:22.196411 1956823808 net.cpp:127] Top shape: 100 128 14 10 (1792000)
I0607 21:45:22.196431 1956823808 layer_factory.hpp:74] Creating layer pool3
I0607 21:45:22.196445 1956823808 net.cpp:90] Creating Layer pool3
I0607 21:45:22.196451 1956823808 net.cpp:410] pool3 <- conv3
I0607 21:45:22.196460 1956823808 net.cpp:368] pool3 -> pool3
I0607 21:45:22.196470 1956823808 net.cpp:120] Setting up pool3
I0607 21:45:22.196539 1956823808 net.cpp:127] Top shape: 100 128 7 5 (448000)
I0607 21:45:22.196552 1956823808 layer_factory.hpp:74] Creating layer ip1
I0607 21:45:22.196563 1956823808 net.cpp:90] Creating Layer ip1
I0607 21:45:22.196570 1956823808 net.cpp:410] ip1 <- pool3
I0607 21:45:22.196580 1956823808 net.cpp:368] ip1 -> ip1
I0607 21:45:22.196595 1956823808 net.cpp:120] Setting up ip1
I0607 21:45:22.213824 1956823808 net.cpp:127] Top shape: 100 500 (50000)
I0607 21:45:22.213850 1956823808 layer_factory.hpp:74] Creating layer relu1
I0607 21:45:22.213862 1956823808 net.cpp:90] Creating Layer relu1
I0607 21:45:22.213867 1956823808 net.cpp:410] relu1 <- ip1
I0607 21:45:22.213872 1956823808 net.cpp:357] relu1 -> ip1 (in-place)
I0607 21:45:22.213881 1956823808 net.cpp:120] Setting up relu1
I0607 21:45:22.214107 1956823808 net.cpp:127] Top shape: 100 500 (50000)
I0607 21:45:22.214139 1956823808 layer_factory.hpp:74] Creating layer ip2
I0607 21:45:22.214162 1956823808 net.cpp:90] Creating Layer ip2
I0607 21:45:22.214169 1956823808 net.cpp:410] ip2 <- ip1
I0607 21:45:22.214176 1956823808 net.cpp:368] ip2 -> ip2
I0607 21:45:22.214184 1956823808 net.cpp:120] Setting up ip2
I0607 21:45:22.214262 1956823808 net.cpp:127] Top shape: 100 10 (1000)
I0607 21:45:22.214295 1956823808 layer_factory.hpp:74] Creating layer feat
I0607 21:45:22.214311 1956823808 net.cpp:90] Creating Layer feat
I0607 21:45:22.214319 1956823808 net.cpp:410] feat <- ip2
I0607 21:45:22.214329 1956823808 net.cpp:368] feat -> feat
I0607 21:45:22.214340 1956823808 net.cpp:120] Setting up feat
I0607 21:45:22.214359 1956823808 net.cpp:127] Top shape: 100 2 (200)
I0607 21:45:22.214385 1956823808 layer_factory.hpp:74] Creating layer conv1_p
I0607 21:45:22.214406 1956823808 net.cpp:90] Creating Layer conv1_p
I0607 21:45:22.214413 1956823808 net.cpp:410] conv1_p <- data_p
I0607 21:45:22.214423 1956823808 net.cpp:368] conv1_p -> conv1_p
I0607 21:45:22.214452 1956823808 net.cpp:120] Setting up conv1_p
I0607 21:45:22.214833 1956823808 net.cpp:127] Top shape: 100 32 60 45 (8640000)
I0607 21:45:22.214846 1956823808 net.cpp:459] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0607 21:45:22.214856 1956823808 net.cpp:459] Sharing parameters 'conv1_b' owned by layer 'conv1', param index 1
I0607 21:45:22.214864 1956823808 layer_factory.hpp:74] Creating layer pool1_p
I0607 21:45:22.214871 1956823808 net.cpp:90] Creating Layer pool1_p
I0607 21:45:22.214875 1956823808 net.cpp:410] pool1_p <- conv1_p
I0607 21:45:22.214928 1956823808 net.cpp:368] pool1_p -> pool1_p
I0607 21:45:22.214942 1956823808 net.cpp:120] Setting up pool1_p
I0607 21:45:22.215029 1956823808 net.cpp:127] Top shape: 100 32 30 23 (2208000)
I0607 21:45:22.215041 1956823808 layer_factory.hpp:74] Creating layer conv2_p
I0607 21:45:22.215049 1956823808 net.cpp:90] Creating Layer conv2_p
I0607 21:45:22.215054 1956823808 net.cpp:410] conv2_p <- pool1_p
I0607 21:45:22.215067 1956823808 net.cpp:368] conv2_p -> conv2_p
I0607 21:45:22.215077 1956823808 net.cpp:120] Setting up conv2_p
I0607 21:45:22.215634 1956823808 net.cpp:127] Top shape: 100 64 29 22 (4083200)
I0607 21:45:22.215651 1956823808 net.cpp:459] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0607 21:45:22.215662 1956823808 net.cpp:459] Sharing parameters 'conv2_b' owned by layer 'conv2', param index 1
I0607 21:45:22.215670 1956823808 layer_factory.hpp:74] Creating layer pool2_p
I0607 21:45:22.215680 1956823808 net.cpp:90] Creating Layer pool2_p
I0607 21:45:22.215688 1956823808 net.cpp:410] pool2_p <- conv2_p
I0607 21:45:22.215699 1956823808 net.cpp:368] pool2_p -> pool2_p
I0607 21:45:22.215713 1956823808 net.cpp:120] Setting up pool2_p
I0607 21:45:22.215783 1956823808 net.cpp:127] Top shape: 100 64 15 11 (1056000)
I0607 21:45:22.215823 1956823808 layer_factory.hpp:74] Creating layer conv3_p
I0607 21:45:22.215844 1956823808 net.cpp:90] Creating Layer conv3_p
I0607 21:45:22.215852 1956823808 net.cpp:410] conv3_p <- pool2_p
I0607 21:45:22.215876 1956823808 net.cpp:368] conv3_p -> conv3_p
I0607 21:45:22.215894 1956823808 net.cpp:120] Setting up conv3_p
I0607 21:45:22.216850 1956823808 net.cpp:127] Top shape: 100 128 14 10 (1792000)
I0607 21:45:22.216887 1956823808 net.cpp:459] Sharing parameters 'conv3_w' owned by layer 'conv3', param index 0
I0607 21:45:22.216903 1956823808 net.cpp:459] Sharing parameters 'conv3_b' owned by layer 'conv3', param index 1
I0607 21:45:22.216912 1956823808 layer_factory.hpp:74] Creating layer pool3_p
I0607 21:45:22.216923 1956823808 net.cpp:90] Creating Layer pool3_p
I0607 21:45:22.216930 1956823808 net.cpp:410] pool3_p <- conv3_p
I0607 21:45:22.216950 1956823808 net.cpp:368] pool3_p -> pool3_p
I0607 21:45:22.216961 1956823808 net.cpp:120] Setting up pool3_p
I0607 21:45:22.217089 1956823808 net.cpp:127] Top shape: 100 128 7 5 (448000)
I0607 21:45:22.217103 1956823808 layer_factory.hpp:74] Creating layer ip1_p
I0607 21:45:22.217111 1956823808 net.cpp:90] Creating Layer ip1_p
I0607 21:45:22.217126 1956823808 net.cpp:410] ip1_p <- pool3_p
I0607 21:45:22.217154 1956823808 net.cpp:368] ip1_p -> ip1_p
I0607 21:45:22.217178 1956823808 net.cpp:120] Setting up ip1_p
I0607 21:45:22.236845 1956823808 net.cpp:127] Top shape: 100 500 (50000)
I0607 21:45:22.236871 1956823808 net.cpp:459] Sharing parameters 'ip1_w' owned by layer 'ip1', param index 0
I0607 21:45:22.236898 1956823808 net.cpp:459] Sharing parameters 'ip1_b' owned by layer 'ip1', param index 1
I0607 21:45:22.236917 1956823808 layer_factory.hpp:74] Creating layer relu1_p
I0607 21:45:22.236928 1956823808 net.cpp:90] Creating Layer relu1_p
I0607 21:45:22.236933 1956823808 net.cpp:410] relu1_p <- ip1_p
I0607 21:45:22.236943 1956823808 net.cpp:357] relu1_p -> ip1_p (in-place)
I0607 21:45:22.236953 1956823808 net.cpp:120] Setting up relu1_p
I0607 21:45:22.237179 1956823808 net.cpp:127] Top shape: 100 500 (50000)
I0607 21:45:22.237193 1956823808 layer_factory.hpp:74] Creating layer ip2_p
I0607 21:45:22.237207 1956823808 net.cpp:90] Creating Layer ip2_p
I0607 21:45:22.237215 1956823808 net.cpp:410] ip2_p <- ip1_p
I0607 21:45:22.237226 1956823808 net.cpp:368] ip2_p -> ip2_p
I0607 21:45:22.237237 1956823808 net.cpp:120] Setting up ip2_p
I0607 21:45:22.237335 1956823808 net.cpp:127] Top shape: 100 10 (1000)
I0607 21:45:22.237347 1956823808 net.cpp:459] Sharing parameters 'ip2_w' owned by layer 'ip2', param index 0
I0607 21:45:22.237367 1956823808 net.cpp:459] Sharing parameters 'ip2_b' owned by layer 'ip2', param index 1
I0607 21:45:22.237390 1956823808 layer_factory.hpp:74] Creating layer feat_p
I0607 21:45:22.237423 1956823808 net.cpp:90] Creating Layer feat_p
I0607 21:45:22.237442 1956823808 net.cpp:410] feat_p <- ip2_p
I0607 21:45:22.237460 1956823808 net.cpp:368] feat_p -> feat_p
I0607 21:45:22.237473 1956823808 net.cpp:120] Setting up feat_p
I0607 21:45:22.237501 1956823808 net.cpp:127] Top shape: 100 2 (200)
I0607 21:45:22.237511 1956823808 net.cpp:459] Sharing parameters 'feat_w' owned by layer 'feat', param index 0
I0607 21:45:22.237519 1956823808 net.cpp:459] Sharing parameters 'feat_b' owned by layer 'feat', param index 1
I0607 21:45:22.237526 1956823808 layer_factory.hpp:74] Creating layer loss
I0607 21:45:22.237594 1956823808 net.cpp:90] Creating Layer loss
I0607 21:45:22.237606 1956823808 net.cpp:410] loss <- feat
I0607 21:45:22.237614 1956823808 net.cpp:410] loss <- feat_p
I0607 21:45:22.237622 1956823808 net.cpp:410] loss <- sim
I0607 21:45:22.237637 1956823808 net.cpp:368] loss -> loss
I0607 21:45:22.237644 1956823808 net.cpp:120] Setting up loss
I0607 21:45:22.237653 1956823808 net.cpp:127] Top shape: (1)
I0607 21:45:22.237658 1956823808 net.cpp:129]     with loss weight 1
I0607 21:45:22.237666 1956823808 net.cpp:192] loss needs backward computation.
I0607 21:45:22.237676 1956823808 net.cpp:192] feat_p needs backward computation.
I0607 21:45:22.237697 1956823808 net.cpp:192] ip2_p needs backward computation.
I0607 21:45:22.237710 1956823808 net.cpp:192] relu1_p needs backward computation.
I0607 21:45:22.237718 1956823808 net.cpp:192] ip1_p needs backward computation.
I0607 21:45:22.237725 1956823808 net.cpp:192] pool3_p needs backward computation.
I0607 21:45:22.237738 1956823808 net.cpp:192] conv3_p needs backward computation.
I0607 21:45:22.237761 1956823808 net.cpp:192] pool2_p needs backward computation.
I0607 21:45:22.237769 1956823808 net.cpp:192] conv2_p needs backward computation.
I0607 21:45:22.237777 1956823808 net.cpp:192] pool1_p needs backward computation.
I0607 21:45:22.237794 1956823808 net.cpp:192] conv1_p needs backward computation.
I0607 21:45:22.237807 1956823808 net.cpp:192] feat needs backward computation.
I0607 21:45:22.237814 1956823808 net.cpp:192] ip2 needs backward computation.
I0607 21:45:22.237833 1956823808 net.cpp:192] relu1 needs backward computation.
I0607 21:45:22.237844 1956823808 net.cpp:192] ip1 needs backward computation.
I0607 21:45:22.237849 1956823808 net.cpp:192] pool3 needs backward computation.
I0607 21:45:22.237854 1956823808 net.cpp:192] conv3 needs backward computation.
I0607 21:45:22.237859 1956823808 net.cpp:192] pool2 needs backward computation.
I0607 21:45:22.237862 1956823808 net.cpp:192] conv2 needs backward computation.
I0607 21:45:22.237866 1956823808 net.cpp:192] pool1 needs backward computation.
I0607 21:45:22.237870 1956823808 net.cpp:192] conv1 needs backward computation.
I0607 21:45:22.237874 1956823808 net.cpp:194] slice_pair does not need backward computation.
I0607 21:45:22.237884 1956823808 net.cpp:194] pair_data does not need backward computation.
I0607 21:45:22.237887 1956823808 net.cpp:235] This network produces output loss
I0607 21:45:22.237898 1956823808 net.cpp:482] Collecting Learning Rate and Weight Decay.
I0607 21:45:22.237906 1956823808 net.cpp:247] Network initialization done.
I0607 21:45:22.237910 1956823808 net.cpp:248] Memory required for data: 151290004
I0607 21:45:22.238029 1956823808 solver.cpp:42] Solver scaffolding done.
I0607 21:45:22.238087 1956823808 solver.cpp:250] Solving siamese_train_validate
I0607 21:45:22.238091 1956823808 solver.cpp:251] Learning Rate Policy: inv
I0607 21:45:22.238704 1956823808 solver.cpp:294] Iteration 0, Testing net (#0)
I0607 21:45:27.567555 1956823808 solver.cpp:343]     Test net output #0: loss = 248.618 (* 1 = 248.618 loss)
I0607 21:45:27.611322 1956823808 solver.cpp:214] Iteration 0, loss = 236.262
I0607 21:45:27.611361 1956823808 solver.cpp:229]     Train net output #0: loss = 236.262 (* 1 = 236.262 loss)
I0607 21:45:27.611373 1956823808 solver.cpp:486] Iteration 0, lr = 0.001
I0607 21:45:39.100541 1956823808 solver.cpp:214] Iteration 100, loss = nan
I0607 21:45:39.100567 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:45:39.100574 1956823808 solver.cpp:486] Iteration 100, lr = 0.000992565
I0607 21:45:50.570935 1956823808 solver.cpp:214] Iteration 200, loss = nan
I0607 21:45:50.570968 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:45:50.570976 1956823808 solver.cpp:486] Iteration 200, lr = 0.000985258
I0607 21:46:02.062310 1956823808 solver.cpp:214] Iteration 300, loss = nan
I0607 21:46:02.062381 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:46:02.062484 1956823808 solver.cpp:486] Iteration 300, lr = 0.000978075
I0607 21:46:13.534807 1956823808 solver.cpp:214] Iteration 400, loss = nan
I0607 21:46:13.534847 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:46:13.534855 1956823808 solver.cpp:486] Iteration 400, lr = 0.000971013
I0607 21:46:24.891914 1956823808 solver.cpp:294] Iteration 500, Testing net (#0)
I0607 21:46:29.994089 1956823808 solver.cpp:343]     Test net output #0: loss = nan (* 1 = nan loss)
I0607 21:46:30.033242 1956823808 solver.cpp:214] Iteration 500, loss = nan
I0607 21:46:30.033282 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:46:30.033288 1956823808 solver.cpp:486] Iteration 500, lr = 0.000964069
I0607 21:46:41.519508 1956823808 solver.cpp:214] Iteration 600, loss = nan
I0607 21:46:41.519558 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:46:41.519664 1956823808 solver.cpp:486] Iteration 600, lr = 0.00095724
I0607 21:46:53.000491 1956823808 solver.cpp:214] Iteration 700, loss = nan
I0607 21:46:53.000530 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:46:53.000636 1956823808 solver.cpp:486] Iteration 700, lr = 0.000950522
I0607 21:47:04.488180 1956823808 solver.cpp:214] Iteration 800, loss = nan
I0607 21:47:04.488214 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:47:04.488221 1956823808 solver.cpp:486] Iteration 800, lr = 0.000943913
I0607 21:47:15.974606 1956823808 solver.cpp:214] Iteration 900, loss = nan
I0607 21:47:15.974655 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:47:15.974673 1956823808 solver.cpp:486] Iteration 900, lr = 0.000937411
I0607 21:47:27.345216 1956823808 solver.cpp:294] Iteration 1000, Testing net (#0)
I0607 21:47:32.446127 1956823808 solver.cpp:343]     Test net output #0: loss = nan (* 1 = nan loss)
I0607 21:47:32.485189 1956823808 solver.cpp:214] Iteration 1000, loss = nan
I0607 21:47:32.485232 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:47:32.485239 1956823808 solver.cpp:486] Iteration 1000, lr = 0.000931013
I0607 21:47:43.965947 1956823808 solver.cpp:214] Iteration 1100, loss = nan
I0607 21:47:43.965986 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:47:43.966090 1956823808 solver.cpp:486] Iteration 1100, lr = 0.000924715
I0607 21:47:55.460681 1956823808 solver.cpp:214] Iteration 1200, loss = nan
I0607 21:47:55.460731 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:47:55.460747 1956823808 solver.cpp:486] Iteration 1200, lr = 0.000918516
I0607 21:48:06.936100 1956823808 solver.cpp:214] Iteration 1300, loss = nan
I0607 21:48:06.936137 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:48:06.936246 1956823808 solver.cpp:486] Iteration 1300, lr = 0.000912412
I0607 21:48:18.413259 1956823808 solver.cpp:214] Iteration 1400, loss = nan
I0607 21:48:18.413297 1956823808 solver.cpp:229]     Train net output #0: loss = nan (* 1 = nan loss)
I0607 21:48:18.413403 1956823808 solver.cpp:486] Iteration 1400, lr = 0.000906403
I0607 21:48:29.869997 1956823808 solver.cpp:361] Snapshotting to src/siamese_network_bw/model/snapshots/siamese_iter_1500.caffemodel
I0607 21:48:29.991000 1956823808 solver.cpp:369] Snapshotting solver state to src/siamese_network_bw/model/snapshots/siamese_iter_1500.solverstate
I0607 21:48:30.113343 1956823808 solver.cpp:276] Iteration 1500, loss = nan
I0607 21:48:30.113368 1956823808 solver.cpp:294] Iteration 1500, Testing net (#0)
I0607 21:48:35.152175 1956823808 solver.cpp:343]     Test net output #0: loss = nan (* 1 = nan loss)
I0607 21:48:35.152201 1956823808 solver.cpp:281] Optimization Done.
I0607 21:48:35.152206 1956823808 caffe.cpp:134] Optimization Done.
